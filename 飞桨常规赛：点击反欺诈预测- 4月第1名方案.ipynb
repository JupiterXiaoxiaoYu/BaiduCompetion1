{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 提交时所使用的checkpoint: ./outputs/ckpt.step480000\n",
    "\n",
    "### 本模型采用XGBoost和百度palm语言模型进行融合，前期做了很多为XGBoost准备的特征工程\n",
    "### 由于深度学习对特征工程的要求不大，故只对palm模型需要的数据进行了缺失值补充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## XGBoost特征处理过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#读取数据集\n",
    "import pandas as pd\n",
    "train= pd.read_csv('./train.csv',encoding='utf-8')\n",
    "test = pd.read_csv('./test1.csv',encoding='utf-8')\n",
    "features = train.drop(['Unnamed: 0','label'],axis=1)\n",
    "labels = train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 因为点击欺诈的一个重要指标就是点击的数量，所以此处构造数量特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#fea1_hash和fea_hash有不同长度，可能代表着用户行为的多少，此处用fea1_hash的长度构建新特征，模型准确度有一定提高（后期可根据不同的数字序列尝试再分类）\n",
    "features['fea1_hash4']=features['fea1_hash'].map(lambda x:len(str(x)))\n",
    "train['fea1_hash4']=test['fea1_hash'].map(lambda x:len(str(x)))    \n",
    "test['fea1_hash4']=test['fea1_hash'].map(lambda x:len(str(x)))\n",
    "\n",
    "#新特征函数，利用数量特征构造。\n",
    "def ded(x):\n",
    "    result = pd.value_counts(x)\n",
    "    x= [result[each] for each in x]\n",
    "    return x\n",
    "\n",
    "#合并测试集和训练集\n",
    "all_df = pd.concat([train,test])\n",
    "\n",
    "#尝试出构造数量特征后有提升的原有特征\n",
    "s = ['dev_height','dev_width','media_id','package','apptype','android_id','fea1_hash','fea_hash']\n",
    "\n",
    "for f in s:\n",
    "    all_df[f]=ded(all_df[f])\n",
    "    train[f+'2'] = all_df[all_df['label'].notnull()][f]\n",
    "    test[f+'2'] = all_df[all_df['label'].isnull()][f]\n",
    "    features[f+'2'] = all_df[all_df['label'].notnull()][f]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据清洗1-osv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据清洗osv\n",
    "def f(x):\n",
    "    if str(x) == 'nan':\n",
    "        return x\n",
    "    else:x = str(x)\n",
    "    y = x\n",
    "    r = '';\n",
    "    for i in range(len(x)):\n",
    "        if x[i].isdigit():\n",
    "            r +=x[i]\n",
    "    if r == '':\n",
    "        return 0\n",
    "    else:\n",
    "        while(r[0]=='0'):\n",
    "            r=r[1:]\n",
    "    k = int((str(r)+'000')[:5])\n",
    "    while(k>12):\n",
    "        k=k/10\n",
    "    return float(k)\n",
    "    \n",
    "train['osv'] = train['osv'].apply(f)\n",
    "features['osv'] = features['osv'].apply(f)\n",
    "test['osv'] = test['osv'].apply(f)\n",
    "\n",
    "\n",
    "#类别特征，后期统一labelencoder\n",
    "cate_features = ['apptype','carrier','ntt','location','cus_type','media_id',\n",
    "'dev_width','dev_height','android_id','fea1_hash']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 新特征构造-利用时间戳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt \n",
    "\"\"\"\n",
    "个人处理日期的想法：直接分桶，分段聚类\n",
    "\"\"\"\n",
    "#处理日期，得到基于小时数的timediff\n",
    "def get_date(features):\n",
    "    features['timestamp'] = features['timestamp'].apply(lambda x: dt.fromtimestamp(x/1000))\n",
    "    start_time = features['timestamp'].min()\n",
    "    features['time_diff'] = features['timestamp'] - start_time\n",
    "    features['time_diff'] = features['time_diff'].dt.days*24 + features['time_diff'].dt.seconds/3600\n",
    "    features.drop(['timestamp'],axis=1,inplace = True)\n",
    "    return features\n",
    "\n",
    "features = get_date(features)\n",
    "test = get_date(test)\n",
    "train = get_date(train)\n",
    "\n",
    "mini = features['time_diff'].min()\n",
    "\n",
    "#尝试出不同的聚类距离，13时提升效果最大\n",
    "def ts(x):\n",
    "    return (x - mini)//13\n",
    "\n",
    "features['time_diff'] = features['time_diff'].apply(ts)\n",
    "train['time_diff'] = train['time_diff'].apply(ts)\n",
    "test['time_diff'] = test['time_diff'].apply(ts)\n",
    "\n",
    "cate_features.append('time_diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 其他数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#去掉过长的特征值\n",
    "features['fea_hash']=features['fea_hash'].map(lambda x:0 if len(str(x))>16 else int(x))\n",
    "features['fea1_hash']=features['fea1_hash'].map(lambda x:0 if len(str(x))>16 else int(x))\n",
    "test['fea_hash']=test['fea_hash'].map(lambda x:0 if len(str(x))>16 else int(x))\n",
    "test['fea1_hash']=test['fea1_hash'].map(lambda x:0 if len(str(x))>16 else int(x))\n",
    "train['fea_hash']=test['fea_hash'].map(lambda x:0 if len(str(x))>16 else int(x))\n",
    "train['fea1_hash']=test['fea1_hash'].map(lambda x:0 if len(str(x))>16 else int(x))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#特征清洗lan\n",
    "# def low(row):\n",
    "#     return row.lower().replace('-',\"\").replace('_',\"\")\n",
    "\n",
    "#将训练集和测试集合并\n",
    "all_df = pd.concat([train,test])\n",
    "all_df['lan']= all_df['lan'].astype('str')#.apply(low)\n",
    "all_df['lan'] = le.fit_transform(all_df['lan'])\n",
    "all_df['fea_hash']= all_df['fea_hash'].astype('str')\n",
    "all_df['fea_hash'] = le.fit_transform(all_df['fea_hash'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#移除不必要的特征\n",
    "nonuse = ['os','sid']\n",
    "col = features.columns.tolist()\n",
    "for i in nonuse:\n",
    "    col.remove(i)\n",
    "features = features[col]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#特征清洗version\n",
    "def rep(x):\n",
    "    if str(x).isdigit():return int(x)\n",
    "    elif str(x)[0] == \"v\" or \"V\":\n",
    "        if str(x)[1:].isdigit():\n",
    "            return int(str(x)[1:])\n",
    "    else:return 0\n",
    "    \n",
    "features['version'] = features['version'].apply(rep)\n",
    "all_df['version'] = all_df['version'].apply(rep)\n",
    "train['version'] = train['version'].apply(rep)\n",
    "\n",
    "#统一labelencoder\n",
    "for fea in cate_features:\n",
    "    all_df[fea]= all_df[fea].astype('float')\n",
    "    all_df[fea] = le.fit_transform(all_df[fea])\n",
    "    \n",
    "features['lan'] = all_df[all_df['label'].notnull()]['lan']\n",
    "features['fea_hash'] = all_df[all_df['label'].notnull()]['fea_hash']\n",
    "\n",
    "train['lan'] = all_df[all_df['label'].notnull()]['lan']\n",
    "train['fea_hash'] = all_df[all_df['label'].notnull()]['fea_hash']\n",
    "\n",
    "for fea in cate_features:\n",
    "    features[fea] = all_df[all_df['label'].notnull()][fea]\n",
    "    train[fea] = all_df[all_df['label'].notnull()][fea]\n",
    "\n",
    "test_fea = test[features.columns]\n",
    "\n",
    "test_fea['lan'] = all_df[all_df['label'].isnull()]['lan']\n",
    "test_fea['fea_hash'] = all_df[all_df['label'].isnull()]['fea_hash']\n",
    "test_fea['version'] = test_fea['version'].apply(rep)\n",
    "\n",
    "for fea in cate_features:\n",
    "    test_fea[fea] = all_df[all_df['label'].isnull()][fea]\n",
    "\n",
    "cate_features.append('lan')\n",
    "features['version']=features['version'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 挑选出没有影响和影响最大的值，剔除或构造新特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android_id\n",
      "apptype\n",
      "dev_height\n",
      "dev_width\n",
      "lan\n",
      "media_id\n",
      "ntt\n",
      "osv\n",
      "package\n",
      "dev_height2\n",
      "dev_width2\n",
      "media_id2\n",
      "package2\n",
      "apptype2\n",
      "android_id2\n",
      "fea1_hash2\n",
      "fea_hash2\n"
     ]
    }
   ],
   "source": [
    "#测试出dev_ppi会使效果下降，放弃使用这个特征\n",
    "f1 = features.drop(['dev_ppi'],axis=1)\n",
    "\n",
    "#挑选出影响最大的特征\n",
    "selected_c = f1.columns\n",
    "def find_key_f(train,selected):\n",
    "    temp0 = train[train['label']==0]\n",
    "    temp = pd.DataFrame(columns=[0,1])\n",
    "    temp[0] = temp0[selected].value_counts()/len(temp0) *100\n",
    "    temp1 = train[train['label']==1]\n",
    "    temp[1] = temp1[selected].value_counts()/len(temp0) *100\n",
    "    temp[2] = temp[1]/temp[0]\n",
    "    result = temp[temp[2]>7].sort_values(2,ascending = False).index\n",
    "    return result\n",
    "\n",
    "kf = {}\n",
    "for selected in selected_c:\n",
    "    kf[selected] = find_key_f(train,selected)\n",
    "\n",
    "#挑选出影响最大的特征值\n",
    "def ff(x,selected):\n",
    "    if x in kf[selected]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for selected in selected_c:\n",
    "    if len(kf[selected])>0:\n",
    "        features[selected+'1'] = features[selected].apply(ff,args = (selected,))\n",
    "        test_fea[selected+'1'] = test_fea[selected].apply(ff,args = (selected,))\n",
    "        print(selected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### XGB 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:11:02] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_child_samples } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "第1个子模型 acc=0.89287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:18:56] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_child_samples } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "第2个子模型 acc=0.89246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:26:54] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_child_samples } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "第3个子模型 acc=0.89266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:31:09] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_child_samples } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "第4个子模型 acc=0.89218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:35:35] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { min_child_samples } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "第5个子模型 acc=0.89286\n",
      "0.892606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9118284 , 0.08817159],\n",
       "       [0.2728742 , 0.72712576],\n",
       "       [0.975502  , 0.02449794],\n",
       "       ...,\n",
       "       [0.03342245, 0.96657753],\n",
       "       [0.04186304, 0.9581369 ],\n",
       "       [0.03877294, 0.96122706]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#五折交叉验证\r\n",
    "import xgboost as xgb\r\n",
    "from sklearn.model_selection import  StratifiedKFold,KFold\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "def ensemble(clf, train_x, train_y, test, cate_features):\r\n",
    "    prob = [] \r\n",
    "    mean_acc = 0 \r\n",
    "    sk = StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\r\n",
    "    for k, (train_i, val_i) in enumerate(sk.split(train_x,train_y)):\r\n",
    "        train_x_real = train_x.iloc[train_i]\r\n",
    "        train_y_real = train_y.iloc[train_i]\r\n",
    "        val_x = train_x.iloc[val_i]\r\n",
    "        val_y = train_y.iloc[val_i]\r\n",
    "        clf = clf.fit(train_x_real,train_y_real)\r\n",
    "        val_y_pred = clf.predict(val_x)\r\n",
    "        acc_val = accuracy_score(val_y,val_y_pred)\r\n",
    "        print(\"第{}个子模型 acc={}\".format(k+1,acc_val))\r\n",
    "        mean_acc += acc_val/5\r\n",
    "        test_y_pred = clf.predict_proba(test)[:-1]\r\n",
    "        prob.append(test_y_pred)\r\n",
    "    print(mean_acc)\r\n",
    "    mean_prob = sum(prob) / 5\r\n",
    "    return mean_prob\r\n",
    "\r\n",
    "\r\n",
    "clf = xgb.XGBClassifier(\r\n",
    "            max_depth=13, learning_rate=0.005, n_estimators=2400, \r\n",
    "            objective='binary:logistic', tree_method='gpu_hist', \r\n",
    "            subsample=0.95, colsample_bytree=0.4, \r\n",
    "            min_child_samples=3, eval_metric='auc', reg_lambda=0.5,\r\n",
    "        )\r\n",
    "ensemble(clf, features, labels, test_fea, cate_features)\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 保存预测结果，方便后续投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_result = clf.predict_proba(test_fea)\r\n",
    "pd.DataFrame(xgb_result).to_csv('xgb_proba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 没有新特征构造的数据处理 - palm模型的数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "import pandas as pd\r\n",
    "train= pd.read_csv('./train.csv',encoding='utf-8')\r\n",
    "test = pd.read_csv('./test1.csv',encoding='utf-8')\r\n",
    "sid = test.sid\r\n",
    "features = train.drop(['Unnamed: 0','label','os','sid'],axis=1)\r\n",
    "labels = train['label']\r\n",
    "test = test[features.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 将时间戳转换为小时数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt \r\n",
    "def get_date(features):\r\n",
    "    features['timestamp'] = features['timestamp'].apply(lambda x: dt.fromtimestamp(x/1000))\r\n",
    "    start_time = features['timestamp'].min()\r\n",
    "    features['time_diff'] = features['timestamp'] - start_time\r\n",
    "    features['time_diff'] = features['time_diff'].dt.days*24 + features['time_diff'].dt.seconds/3600\r\n",
    "    features.drop(['timestamp'],axis=1,inplace = True)\r\n",
    "    return features\r\n",
    "\r\n",
    "features = get_date(features)\r\n",
    "test = get_date(test)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#取整\r\n",
    "features.time_diff = features.time_diff.astype(int)\r\n",
    "test.time_diff = test.time_diff.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.loc[:,\"osv\"] = features.loc[:,\"osv\"].fillna(test.loc[:,\"osv\"].mode()[0]) \r\n",
    "features.loc[:,\"lan\"] = features.loc[:,\"lan\"].fillna('nan')\r\n",
    "\r\n",
    "test.loc[:,\"osv\"] = test.loc[:,\"osv\"].fillna(test.loc[:,\"osv\"].mode()[0])\r\n",
    "test.loc[:,\"lan\"] = test.loc[:,\"lan\"].fillna('nan') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 将特征分为两类，一类是用户信息，一类是媒体信息，将他们的信息分别用空格连接起来变成两个句子，每个特征相当于句子中的一个词语，以用户和媒体信息之间的这种点击关系去做一个类似问答的任务，用户信息放在了text_a,媒体信息放在了text_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#连接函数\r\n",
    "\r\n",
    "def sentence(row):\r\n",
    "    return ' '.join([str(row[i]) for i in int_type])\r\n",
    "\r\n",
    "\r\n",
    "def sentence1(row):\r\n",
    "    return ' '.join([str(row[i]) for i in string_type])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#提取媒体信息和用户信息\r\n",
    "string_type =['package','apptype','version','android_id','media_id']\r\n",
    "int_type = []\r\n",
    "for i in features.columns:\r\n",
    "    if i not in string_type:\r\n",
    "        int_type.append(i)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#写入palm的训练和预测数据\r\n",
    "train_palm = pd.DataFrame()\r\n",
    "train_palm['label'] = train['label']\r\n",
    "train_palm['text_a'] = features[int_type].apply(sentence,axis=1)\r\n",
    "train_palm['text_b'] = features[string_type].apply(sentence1,axis=1)\r\n",
    "\r\n",
    "test_palm = pd.DataFrame()\r\n",
    "test_palm['label'] = test.apptype #label不能为空，可以随便填一个\r\n",
    "test_palm['text_a'] = test[int_type].apply(sentence,axis=1)\r\n",
    "test_palm['text_b'] = test[string_type].apply(sentence1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#保存palm所需的数据\r\n",
    "train_palm.to_csv('./train_palm.csv', sep='\\t', index=False)\r\n",
    "test_palm.to_csv('./test_palm.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### palm模型搭建与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: paddlepalm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.2)\n",
      "Requirement already satisfied: paddlepaddle-gpu>=1.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepalm) (2.0.2.post101)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu>=1.7.0->paddlepalm) (7.1.2)\n",
      "Requirement already satisfied: gast>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu>=1.7.0->paddlepalm) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu>=1.7.0->paddlepalm) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu>=1.7.0->paddlepalm) (1.20.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu>=1.7.0->paddlepalm) (4.4.0)\n",
      "Requirement already satisfied: astor in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu>=1.7.0->paddlepalm) (0.8.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu>=1.7.0->paddlepalm) (2.22.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu>=1.7.0->paddlepalm) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu>=1.7.0->paddlepalm) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu>=1.7.0->paddlepalm) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu>=1.7.0->paddlepalm) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu>=1.7.0->paddlepalm) (1.25.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlepalm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 查看并下载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available pretrain items:\n",
      "  => RoBERTa-zh-base\n",
      "  => RoBERTa-zh-large\n",
      "  => ERNIE-v2-en-base\n",
      "  => ERNIE-v2-en-large\n",
      "  => XLNet-cased-base\n",
      "  => XLNet-cased-large\n",
      "  => ERNIE-v1-zh-base\n",
      "  => ERNIE-v1-zh-base-max-len-512\n",
      "  => BERT-en-uncased-large-whole-word-masking\n",
      "  => BERT-en-cased-large-whole-word-masking\n",
      "  => BERT-en-uncased-base\n",
      "  => BERT-en-uncased-large\n",
      "  => BERT-en-cased-base\n",
      "  => BERT-en-cased-large\n",
      "  => BERT-multilingual-uncased-base\n",
      "  => BERT-multilingual-cased-base\n",
      "  => BERT-zh-base\n"
     ]
    }
   ],
   "source": [
    "from paddlepalm import downloader\r\n",
    "downloader.ls('pretrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrain: ERNIE-v2-en-base from https://ernie.bj.bcebos.com/ERNIE_Base_en_stable-2.0.0.tar.gz...\n",
      ">> Downloading... 100.0% done!\n",
      "Extracting ERNIE_Base_en_stable-2.0.0.tar.gz... done!\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "downloader.download('pretrain', 'ERNIE-v2-en-base', './pretrain_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import json\r\n",
    "import paddlepalm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 设置palm参数，开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_seqlen = 128\r\n",
    "batch_size = 16\r\n",
    "num_epochs = 30\r\n",
    "lr = 1e-6\r\n",
    "weight_decay = 0.0001\r\n",
    "num_classes = 2\r\n",
    "random_seed = 1\r\n",
    "dropout_prob = 0.002\r\n",
    "save_path = './outputs/'\r\n",
    "save_type = 'ckpt'\r\n",
    "pred_model_path = './outputs/ckpt.step15000'\r\n",
    "print_steps = 1000\r\n",
    "pred_output = './outputs/predict/'\r\n",
    "pre_params =  '/home/aistudio/pretrain_models/pretrain/ERNIE-v2-en-base/params'\r\n",
    "task_name = 'Quora Question Pairs matching'\r\n",
    "vocab_path = '/home/aistudio/pretrain_models/pretrain/ERNIE-v2-en-base/vocab.txt'\r\n",
    "train_file = '/home/aistudio/train_palm.csv'\r\n",
    "predict_file = '/home/aistudio/test_palm.csv'\r\n",
    "config = json.load(open('/home/aistudio/pretrain_models/pretrain/ERNIE-v2-en-base/ernie_config.json'))\r\n",
    "input_dim = config['hidden_size']\r\n",
    "paddle.enable_static()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlepalm/backbone/ernie.py:180\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlepalm/backbone/ernie.py:181\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlepalm/backbone/ernie.py:191\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlepalm/backbone/utils/transformer.py:148\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlepalm/backbone/utils/transformer.py:237\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:687: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif dtype == np.bool:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n",
      "Loading pretraining parameters from /home/aistudio/pretrain_models/pretrain/ERNIE-v2-en-base/params...\n",
      "Warning: Quora Question Pairs matching.cls_out_w not found in /home/aistudio/pretrain_models/pretrain/ERNIE-v2-en-base/params.\n",
      "Warning: Quora Question Pairs matching.cls_out_b not found in /home/aistudio/pretrain_models/pretrain/ERNIE-v2-en-base/params.\n",
      "\n",
      "step 1000/31250 (epoch 0), loss: 0.659, speed: 12.84 steps/s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-702f39d4d1f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# step 8-3: start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m# 预测部分代码，假设训练保存模型为./outputs/training_pred_model：\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prepare to predict...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlepalm/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, print_steps)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mtime_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mrt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m             \u001b[0;31m# if gpu_dev_count > 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;31m#     feed, mask = feed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlepalm/trainer.py\u001b[0m in \u001b[0;36mtrain_one_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_batch_process_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mrt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribute_train_prog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mrt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                 \u001b[0muse_program_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_program_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0muse_prune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_prune\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m                 return_merged=return_merged)\n\u001b[0m\u001b[1;32m   1109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_impl\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache, return_merged, use_prune)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                 \u001b[0mfetch_var_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_var_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0mreturn_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_numpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                 return_merged=return_merged)\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     def _run_program(self, program, feed, fetch_list, feed_var_name,\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_parallel\u001b[0;34m(self, program, scope, feed, fetch_list, fetch_var_name, return_numpy, return_merged)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mfetch_var_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_name_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_var_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_merged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mas_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_numpy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\r\n",
    "\r\n",
    "match_reader = paddlepalm.reader.MatchReader(vocab_path, max_seqlen, seed=random_seed)\r\n",
    "# step 1-2: load the training data\r\n",
    "match_reader.load_data(train_file, file_format='tsv', num_epochs=num_epochs, batch_size=batch_size)\r\n",
    "# step 2: create a backbone of the model to extract text features\r\n",
    "ernie = paddlepalm.backbone.ERNIE.from_config(config)\r\n",
    "# step 3: register the backbone in reader\r\n",
    "match_reader.register_with(ernie)\r\n",
    "# step 4: create the task output head\r\n",
    "match_head = paddlepalm.head.Match(num_classes, input_dim, dropout_prob)\r\n",
    "# step 5-1: create a task trainer\r\n",
    "trainer = paddlepalm.Trainer(task_name)\r\n",
    "# step 5-2: build forward graph with backbone and task head\r\n",
    "\r\n",
    "loss_var = trainer.build_forward(ernie, match_head)\r\n",
    "# step 6-1*: use warmup\r\n",
    "n_steps = match_reader.num_examples * num_epochs // batch_size\r\n",
    "warmup_steps = int(0.1 * n_steps)\r\n",
    "sched = paddlepalm.lr_sched.TriangularSchedualer(warmup_steps, n_steps)\r\n",
    "# step 6-2: create a optimizer\r\n",
    "adam = paddlepalm.optimizer.Adam(loss_var, lr, sched)\r\n",
    "# step 6-3: build backward\r\n",
    "trainer.build_backward(optimizer=adam, weight_decay=weight_decay)\r\n",
    "# step 7: fit prepared reader and data\r\n",
    "trainer.fit_reader(match_reader)\r\n",
    "# step 8-1*: load pretrained parameters\r\n",
    "trainer.load_pretrain(pre_params, False)\r\n",
    "# step 8-2*: set saver to save model\r\n",
    "save_steps = 15000\r\n",
    "trainer.set_saver(save_path=save_path, save_steps=save_steps, save_type=save_type)\r\n",
    "# step 8-3: start training\r\n",
    "trainer.train(print_steps=print_steps)\r\n",
    "# 预测部分代码，假设训练保存模型为./outputs/training_pred_model：\r\n",
    "print('prepare to predict...')\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 使用480000step预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_path = '/home/aistudio/pretrain_models/pretrain/ERNIE-v2-en-base/vocab.txt'\r\n",
    "\r\n",
    "predict_match_reader = paddlepalm.reader.MatchReader(vocab_path, max_seqlen, seed=random_seed, phase='predict')\r\n",
    "# step 1-2: load the training data\r\n",
    "predict_match_reader.load_data(predict_file, batch_size)\r\n",
    "# step 2: create a backbone of the model to extract text features\r\n",
    "pred_ernie = paddlepalm.backbone.ERNIE.from_config(config, phase='predict')\r\n",
    "# step 3: register the backbone in reader\r\n",
    "predict_match_reader.register_with(pred_ernie)\r\n",
    "# step 4: create the task output head\r\n",
    "match_pred_head = paddlepalm.head.Match(num_classes, input_dim, phase='predict')\r\n",
    "predicter=paddlepalm.Trainer(task_name)\r\n",
    "# step 5: build forward graph with backbone and task head\r\n",
    "predicter.build_predict_forward(pred_ernie, match_pred_head)\r\n",
    "\r\n",
    "pred_model_path ='./outputs/ckpt.step480000'\r\n",
    "# step 6: load pretrained model\r\n",
    "pred_ckpt = predicter.load_ckpt(pred_model_path)\r\n",
    "# step 7: fit prepared reader and data\r\n",
    "predicter.fit_reader(predict_match_reader, phase='predict')\r\n",
    "\r\n",
    "# step 8: predict\r\n",
    "print('predicting..')\r\n",
    "predicter.predict(print_steps=print_steps, output_dir=pred_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 读取palm预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "palm_proba = pd.read_json('./outputs/predict/predictions.json',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 获取palm预测中为欺诈点击的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "palm_res = palm_proba.probs.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 读取xgboost的预测概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_result = pd.read_csv('./xgb_proba.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 将XGBoost和palm的预测结果相加，用1作为阀值投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.119056\n",
       "1         1.440423\n",
       "2         0.080029\n",
       "3         0.048663\n",
       "4         1.920310\n",
       "            ...   \n",
       "149995    1.868549\n",
       "149996    1.923986\n",
       "149997    1.897405\n",
       "149998    1.939416\n",
       "149999    1.930932\n",
       "Length: 150000, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "palm_label = palm_proba.label\r\n",
    "vote = xgb_result['1'] + palm_res\r\n",
    "vote = pd.DataFrame(vote)\r\n",
    "result = vote[0].apply(lambda x:1 if x>=1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 最终结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame(sid)\r\n",
    "a['label']= result\r\n",
    "a.to_csv('composition.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
